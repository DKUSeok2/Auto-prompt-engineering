import os
import ollama
from typing import List, Dict, Optional

class JejuTravelChatbot:
    def __init__(self, model_name: str = "gemma3:4b"):
        """
        ì œì£¼ë„ ì—¬í–‰ ì±—ë´‡ ì´ˆê¸°í™”
        
        Args:
            model_name: Ollama ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gemma3:4b)
        """
        self.model_name = model_name
        self.conversation_history = []
        
        # ChromaDB ì—°ê²° (ì´ë¯¸ ë¡œë”©ëœ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
        try:
            self.client, self.collection = self.connect_to_existing_db()
            print("âœ… ChromaDB ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ data_loader.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì„œ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì„¸ìš”.")
            self.client = None
            self.collection = None
    
    def connect_to_existing_db(self):
        """
        ì´ë¯¸ ë¡œë”©ëœ ChromaDBì— ì—°ê²°
        
        Returns:
            client, collection: ChromaDB í´ë¼ì´ì–¸íŠ¸ì™€ ì»¬ë ‰ì…˜
        """
        import chromadb
        from chromadb.utils.embedding_functions import EmbeddingFunction
        from langchain_upstage import UpstageEmbeddings
        from dotenv import load_dotenv
        
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
        load_dotenv()
        api_key = os.getenv("UPSTAGE_API_KEY")
        if not api_key:
            raise ValueError("UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # Upstage ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        passage_embedder = UpstageEmbeddings(model="solar-embedding-1-large-passage")
        
        # EmbeddingFunction ë˜í¼ ì •ì˜
        class UpstageEmbeddingFunction(EmbeddingFunction):
            def __init__(self, embedder):
                self.embedder = embedder

            def __call__(self, input):
                try:
                    # inputì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if isinstance(input, str):
                        input = [input]
                    return [self.embedder.embed_query(text) for text in input]
                except Exception as e:
                    raise RuntimeError(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        if not os.path.exists("./chroma_db"):
            raise FileNotFoundError("ChromaDB ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. data_loader.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=chromadb.Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
        collection = client.get_collection(
            name="visitjeju",
            embedding_function=UpstageEmbeddingFunction(passage_embedder)
        )
        
        return client, collection
    
    def load_prompt(self, prompt_file: str = "prompt.txt") -> str:
        """
        í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
        
        Args:
            prompt_file: í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            í”„ë¡¬í”„íŠ¸ ë‚´ìš©
        """
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return "ë‹¹ì‹ ì€ ì œì£¼ë„ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì—¬í–‰ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."
    
    def search_relevant_info(self, query: str, n_results: int = 3) -> List[Dict]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ì— ê´€ë ¨ëœ ì •ë³´ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            n_results: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.collection:
            return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            from langchain_upstage import UpstageEmbeddings
            from dotenv import load_dotenv
            
            load_dotenv()
            query_embedder = UpstageEmbeddings(model="solar-embedding-1-large-query")
            query_embedding = query_embedder.embed_query(query)
            
            # ê²€ìƒ‰ ì‹¤í–‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results
            )
            
            # ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬
            relevant_info = []
            if results and 'metadatas' in results:
                for i, metadata in enumerate(results['metadatas'][0]):
                    info = {
                        'name': metadata.get('ì´ë¦„', metadata.get('title', 'ì œëª© ì—†ìŒ')),
                        'category': metadata.get('category', 'ì¹´í…Œê³ ë¦¬ ì—†ìŒ'),
                        'address': metadata.get('ì£¼ì†Œ', metadata.get('roadaddress', 'ì£¼ì†Œ ì—†ìŒ')),
                        'phone': metadata.get('ì „í™”ë²ˆí˜¸', 'ì „í™”ë²ˆí˜¸ ì—†ìŒ'),
                        'tags': metadata.get('íƒœê·¸', metadata.get('alltag', 'íƒœê·¸ ì—†ìŒ')),
                        'description': metadata.get('ì†Œê°œ', metadata.get('introduction', 'ì„¤ëª… ì—†ìŒ')),
                        'distance': results.get('distances', [[]])[0][i] if results.get('distances') else 0
                    }
                    relevant_info.append(info)
            
            return relevant_info
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def format_context(self, relevant_info: List[Dict]) -> str:
        """
        ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
        
        Args:
            relevant_info: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        if not relevant_info:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context = "=== ì œì£¼ë„ ê´€ë ¨ ì •ë³´ ===\n\n"
        
        for i, info in enumerate(relevant_info, 1):
            context += f"{i}. {info['name']} ({info['category']})\n"
            context += f"   ğŸ“ ì£¼ì†Œ: {info['address']}\n"
            if info['phone'] != 'ì „í™”ë²ˆí˜¸ ì—†ìŒ':
                context += f"   ğŸ“ ì „í™”ë²ˆí˜¸: {info['phone']}\n"
            context += f"   ğŸ· íƒœê·¸: {info['tags']}\n"
            context += f"   ğŸ’¬ ì„¤ëª…: {info['description']}\n"
            context += f"   ğŸ“Š ê´€ë ¨ë„: {info['distance']:.3f}\n\n"
        
        return context
    
    def generate_response(self, user_input: str) -> str:
        """
        ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            
        Returns:
            ì±—ë´‡ ì‘ë‹µ
        """
        # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        system_prompt = self.load_prompt()
        
        # ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
        relevant_info = self.search_relevant_info(user_input)
        context = self.format_context(relevant_info)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
        conversation_context = ""
        if self.conversation_history:
            conversation_context = "\n=== ì´ì „ ëŒ€í™” ===\n"
            for i, (user_msg, bot_msg) in enumerate(self.conversation_history[-3:], 1):  # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ
                conversation_context += f"ì‚¬ìš©ì {i}: {user_msg}\n"
                conversation_context += f"ì±—ë´‡ {i}: {bot_msg}\n\n"
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        full_prompt = f"""
{system_prompt}

{context}

{conversation_context}

í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ìœ„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        
        try:
            # Ollama API í˜¸ì¶œ
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {
                        'role': 'system',
                        'content': system_prompt
                    },
                    {
                        'role': 'user', 
                        'content': f"{context}\n\n{conversation_context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
                    }
                ]
            )
            
            bot_response = response['message']['content']
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append((user_input, bot_response))
            
            return bot_response
            
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
        print("âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_conversation_history(self) -> List[tuple]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.conversation_history
    
    def set_model(self, model_name: str):
        """ëª¨ë¸ ë³€ê²½"""
        self.model_name = model_name
        print(f"âœ… ëª¨ë¸ì´ {model_name}ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # ì±—ë´‡ ì´ˆê¸°í™”
    chatbot = JejuTravelChatbot()
    
    print("ğŸï¸ ì œì£¼ë„ ì—¬í–‰ ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ë ¤ë©´ 'clear'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("-" * 50)
    
    while True:
        user_input = input("\nì‚¬ìš©ì: ")
        
        if user_input.lower() in ['quit', 'exit']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        elif user_input.lower() == 'clear':
            chatbot.clear_history()
            continue
        elif user_input.strip() == '':
            continue
        
        print("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
        response = chatbot.generate_response(user_input)
        print(f"\nì±—ë´‡: {response}")
        print("-" * 50) 