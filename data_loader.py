import os
import pandas as pd
from tqdm import tqdm
from dotenv import load_dotenv
import chromadb
from chromadb.utils.embedding_functions import EmbeddingFunction
from langchain_upstage import UpstageEmbeddings

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
api_key = os.getenv("UPSTAGE_API_KEY")
if not api_key:
    raise ValueError("UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

print("ğŸ”‘ API Key í™•ì¸ ì™„ë£Œ")

# 2. Upstage ì„ë² ë”© ëª¨ë¸ ì„¤ì •
try:
    print("âš¡ Upstage ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
    query_embedder = UpstageEmbeddings(model="solar-embedding-1-large-query")
    passage_embedder = UpstageEmbeddings(model="solar-embedding-1-large-passage")
    print("âœ… Upstage ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
except Exception as e:
    raise RuntimeError(f"Upstage ì„ë² ë”© ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# 3. ChromaDBì— ì‚¬ìš©í•  EmbeddingFunction ë˜í¼ ì •ì˜
class UpstageEmbeddingFunction(EmbeddingFunction):
    def __init__(self, embedder):
        self.embedder = embedder

    def __call__(self, input):
        try:
            # inputì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(input, str):
                input = [input]
            return [self.embedder.embed_query(text) for text in input]
        except Exception as e:
            raise RuntimeError(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# 4. ChromaDB ì´ˆê¸°í™”
print("ğŸ—„ï¸ ChromaDB ì´ˆê¸°í™” ì¤‘...")
try:
    # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ (ìƒˆë¡œ ì‹œì‘)
    import shutil
    if os.path.exists("./chroma_db"):
        shutil.rmtree("./chroma_db")
    
    client = chromadb.PersistentClient(
        path="./chroma_db",
        settings=chromadb.Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )
    collection = client.get_or_create_collection(
        name="visitjeju",
        embedding_function=UpstageEmbeddingFunction(passage_embedder)
    )
    print("âœ… ChromaDB ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    raise

# 5. íŒŒì¼-ì¹´í…Œê³ ë¦¬ ë§¤í•‘
category_map = {
    "data/visitjeju_food.json": "ìŒì‹",
    "data/visitjeju_hotel.json": "ìˆ™ì†Œ",
    "data/visitjeju_tour.json": "ê´€ê´‘ì§€",
    "data/visitjeju_event.json": "í–‰ì‚¬"
}

print("ğŸ“‚ ë°ì´í„° íŒŒì¼ í™•ì¸ ì¤‘...")
for filename in category_map.keys():
    if os.path.exists(filename):
        print(f"âœ… {filename} íŒŒì¼ ì¡´ì¬")
    else:
        print(f"âš ï¸ {filename} íŒŒì¼ ì—†ìŒ")

# 6. íŒŒì¼ ìˆœíšŒí•˜ë©° ì„ë² ë”© ë° ì €ì¥
total_processed = 0

for filename, category in category_map.items():
    if not os.path.exists(filename):
        print(f"â­ï¸ {filename} íŒŒì¼ì´ ì—†ì–´ ê±´ë„ˆëœ€")
        continue
        
    try:
        df = pd.read_json(filename)
        print(f"ğŸ“Š {filename}: {len(df)}ê°œ ë°ì´í„° ë¡œë“œ")
    except Exception as e:
        print(f"âŒ {filename} ë¡œë”© ì‹¤íŒ¨: {e}")
        continue

    ids, documents, metadatas = [], [], []

    for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=f"ğŸ“‚ {filename} ì²˜ë¦¬ ì¤‘"):
        try:
            metadata = row.to_dict()

            # ì¹´í…Œê³ ë¦¬ë³„ document êµ¬ì„±
            if category == "ìŒì‹":
                content = (
                    f"ì¹´í…Œê³ ë¦¬: ìŒì‹ "
                    f"ì´ë¦„: {row.get('ì´ë¦„', '')} "
                    f"ì£¼ì†Œ: {row.get('ì£¼ì†Œ', '')} "
                    f"ì†Œê°œ: {row.get('ì†Œê°œ', '')} "
                    f"íƒœê·¸: {row.get('íƒœê·¸', '')} "
                )
            elif category == "ìˆ™ì†Œ":
                content = (
                    f"ì¹´í…Œê³ ë¦¬: ìˆ™ì†Œ "
                    f"ì´ë¦„: {row.get('ì´ë¦„', '')} "
                    f"ì£¼ì†Œ: {row.get('ì£¼ì†Œ', '')} "
                    f"ì „í™”ë²ˆí˜¸: {row.get('ì „í™”ë²ˆí˜¸', '')} "
                    f"ì†Œê°œ: {row.get('ì†Œê°œ', '')}"
                    f"íƒœê·¸: {row.get('íƒœê·¸', '')} "
                )
            elif category == "ê´€ê´‘ì§€":
                content = (
                    f"ì¹´í…Œê³ ë¦¬: ê´€ê´‘ì§€ "
                    f"ì´ë¦„: {row.get('ì´ë¦„', '')} "
                    f"ì£¼ì†Œ: {row.get('ì£¼ì†Œ', '')} "
                    f"ì „í™”ë²ˆí˜¸: {row.get('ì „í™”ë²ˆí˜¸', '')} "
                    f"ì†Œê°œ: {row.get('ì†Œê°œ', '')}"
                    f"íƒœê·¸: {row.get('íƒœê·¸', '')} "
                )
            elif category == "í–‰ì‚¬":
                content = (
                    f"ì¹´í…Œê³ ë¦¬: í–‰ì‚¬ "
                    f"ì´ë¦„: {row.get('title', '')} "
                    f"ì£¼ì†Œ: {row.get('roadaddress', '')} "
                    f"íƒœê·¸: {row.get('alltag', '')} "
                    f"ì†Œê°œ: {row.get('introduction', '')}"
                )
            else:
                content = "ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ"

            ids.append(f"{category}_{i}")
            documents.append(content)
            metadatas.append({**metadata, "category": category, **{key: value if value is not None else '' for key, value in metadata.items()}})
        except Exception as e:
            print(f"{i}ë²ˆì§¸ í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì €ì¥
    batch_size = 100
    for batch_start in range(0, len(ids), batch_size):
        batch_end = batch_start + batch_size
        try:
            collection.add(
                ids=ids[batch_start:batch_end],
                documents=documents[batch_start:batch_end],
                metadatas=metadatas[batch_start:batch_end]
            )
            print(f"âœ… {filename} â†’ {batch_start}~{batch_end}ë²ˆ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ {filename} â†’ {batch_start}~{batch_end} ì €ì¥ ì‹¤íŒ¨: {e}")

    total_processed += len(ids)
    print(f"ğŸ“Š {filename} ì²˜ë¦¬ ì™„ë£Œ: {len(ids)}ê°œ ë°ì´í„°")

print(f"\nğŸ‰ ì „ì²´ ë°ì´í„° ë¡œë”© ì™„ë£Œ! ì´ {total_processed}ê°œ ë°ì´í„° ì²˜ë¦¬")

# 7. ì˜ˆì‹œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
print("\nğŸ§ª ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
query_text = "ì œì£¼ ê°ì„± ì¹´í˜ ì¶”ì²œí•´ì¤˜"
try:
    query_embedding = query_embedder.embed_query(query_text)
    print(f"âœ… ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ: '{query_text}'")
except Exception as e:
    raise RuntimeError(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# 8. ê²€ìƒ‰ ì‹¤í–‰
try:
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=3
    )
    print("âœ… ê²€ìƒ‰ ì‹¤í–‰ ì™„ë£Œ")
except Exception as e:
    raise RuntimeError(f"ChromaDB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# 9. ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ” '{query_text}' ê²€ìƒ‰ ê²°ê³¼:")
print("=" * 60)
for i, metadata in enumerate(results.get('metadatas', [[]])[0]):
    print(f"[{i+1}] {metadata.get('ì´ë¦„', metadata.get('title', 'ì œëª© ì—†ìŒ'))} ({metadata.get('category', 'ì¹´í…Œê³ ë¦¬ ì—†ìŒ')})")
    print(f"ğŸ“ ì£¼ì†Œ: {metadata.get('ì£¼ì†Œ', metadata.get('roadaddress', 'ì—†ìŒ'))}")
    print(f"ğŸ“ ì „í™”ë²ˆí˜¸: {metadata.get('ì „í™”ë²ˆí˜¸', 'ì—†ìŒ')}")
    print(f"ğŸ· íƒœê·¸: {metadata.get('íƒœê·¸', metadata.get('alltag', 'ì—†ìŒ'))}")
    print(f"ğŸ’¬ ì„¤ëª…: {metadata.get('ì†Œê°œ', metadata.get('introduction', 'ì—†ìŒ'))}")
    print("-" * 50)

# 10. ìœ ì‚¬ë„ ê±°ë¦¬ ì¶œë ¥
print("\nğŸ“ ìœ ì‚¬ë„ ê±°ë¦¬:")
for i, (metadata, distance) in enumerate(zip(results.get('metadatas', [[]])[0], results.get('distances', [[]])[0])):
    name = metadata.get('ì´ë¦„', metadata.get('title', 'ì œëª© ì—†ìŒ'))
    print(f"[{i+1}] {name} (ìœ ì‚¬ë„ ê±°ë¦¬: {distance:.4f})")

print("\nğŸ¯ ë°ì´í„° ë¡œë” ì‹¤í–‰ ì™„ë£Œ!")
print("ì´ì œ Streamlit ì•±ì—ì„œ ChromaDBë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
print("ì‹¤í–‰ ëª…ë ¹ì–´: streamlit run app.py") 